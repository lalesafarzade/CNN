{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from callback import myCallback\n",
    "from modelling import mnist_model_creating\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflowjs as tfjs\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(): \n",
    "  model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lales\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4759\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3590\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3199\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2993\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2800\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2665\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2534\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2432\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2319\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2212\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2174\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2096\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1995\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1919\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.1859\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1808\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1731\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1699\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1634\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1596\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1553\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1496\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1436\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1453\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1372\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1364\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1329\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1282\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1276\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1210\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1209\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1149\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1148\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1108\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1099\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1056\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1047\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.1044\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1002\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0998\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0976\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0949\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0924\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.0903\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0893\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0875\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0859\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0848\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0792\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0829\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0778\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0802\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0743\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0760\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0747\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0735\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.07300s - l\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0718\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0701\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0679\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0703\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0677\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0684\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0645\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0618\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0637\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0635\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0603\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0595\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0590\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0583\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0602\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0551\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0564\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0558\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0533\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0582\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0541\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0535\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0539\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0497\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0543\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0475\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0487\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0507\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0491\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0468\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0462\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0486\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0445\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0494\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.0439\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0489\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0446\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0438\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0431\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0462\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0441\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0448\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x274b9013f48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = create_model()\n",
    "model.fit(training_images, training_labels, epochs=100, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('MODELS/my_fashion')\n",
    "#model.save('MODELS/my_fashion.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               692352    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022AD14AEDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022AD14AEDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1452 - accuracy: 0.9575\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0502 - accuracy: 0.9847\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0316 - accuracy: 0.9901\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0133 - accuracy: 0.9961\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0102 - accuracy: 0.9967\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022AD1984DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022AD1984DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9870\n",
      "0.9869999885559082\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9870\n",
      "0.9869999885559082\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('MODELS/fashion/fashion')\n",
    "#model.save('MODELS/fashion/fashion.h5')\n",
    "#tfjs.converters.save_keras_model(model,\"MODELS/fashion/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4936925e-18 8.8774142e-14 1.4255640e-13 3.6468120e-12 9.7160191e-17 4.5181661e-15 1.0040760e-20 1.0000000e+00 4.7726915e-18 1.0165536e-12]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(classifications[17])\n",
    "\n",
    "print(test_labels[17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d8252e6ff2fcf763984e1fe66594d90dbe24607a75b4fe465f6934f23ce49e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
